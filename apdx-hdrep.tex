\chapter{Comparisons of the uniform and cosine similarity intercept distributions}\label{apdx:hdrep}
\Cref{tbl:csdist} summarizes the change in error over a wide range of parameters when switching from a uniform intercept distribution to the $\csdist(\dims + 2)$ distribution.
In general, the cosine similarity distribution performs better.
It performs equal to the uniform distribution for $\dims = 1$ in which case $\csdist(\dims + 2)$ reduces to a uniform distribution and rectified linear (rate) neurons with a regularization of $\gamma = 0.1$.
The cosine similarity distribution performs slightly worse for rate neurons (LIF rate and rectified linear) when the regularization is adjusted to $\gamma = 0.01$ to account for the non-existent spiking noise.
The only other case with slightly worse performance is when computing pairwise products $y_i = x_{2i - 2} x_{2i - 1},\ 1 \leq i \leq i/2$, but note that no further optimization for this sort of function has been done and the high dimensionality makes this a hard function to compute.
On the simpler squaring, the cosine similarity distribution performs better.
\begin{table}
    \caption{Change in representational error in the NEF when switching from uniformly distributed intercepts to $\csdist(\dims + 2)$ distributed intercepts for different dimensionalities $\dims$, neuron numbers $n$, synaptic time constants $\syntau$, decoded functions, regularization $\gamma$, and neuron types.
A negative change in error (highlighted red) means that the cosine similarity distribution performed better.
Statistical significance determined with bootstrapping is marked with **** for $p < 0.0001$ and * for $p < 0.05$.}\label{tbl:csdist}
    \scriptsize
    \input{tables/hdrep.tex}
\end{table}
