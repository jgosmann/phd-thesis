\chapter{Recalling items}
In the original TCM model (TODO ref) the activations $a_i$ of items in the memory is mapped to a recall probability by a softmax function
\begin{equation}
    P(\tcmitem_i | \ctx) = \frac{\exp(2a_i/\tau)}{\sum_j \exp(2a_j/\tau)}
\end{equation}
with a free parameter $\tau$ controlling for the sensitivity.
While this does well in capturing the recall probabilities, it does not provide much insight in how this recall process might be realized neurally.
In an extension of the TCM model (TODO ref) a winner-take-all (WTA) process based on the widely-used leaky, competing accumulator (LCA) model by TODO ref was used.
This works well if the output can be evaluated in a mathematical analysis.
However, within the CUE model other parts of the model need to recognize when a single recall is completed to update the context and reset the recall system.
As I will show, this is difficult to do robustly with the LCA model, but more easily with an alternate WTA mechanism termed the independent accumulator (IA) model.
A comparison of these two networks has also been previously published as TODO ref.


\section{Leaky, competing accumulator model}
Given $D$ choices, the leaky, competing accumulator (LCA) model proposed by TODO ref describes the dynamics of $D$ scalar state variables $x_i(t), 1 \leq i \leq D$ as
\begin{equation}
    \od{x_i}{t} = \frac{1}{\tau} \del{u_i(t) -\kappa x_i - \lambda \sum_{j \neq i} x_j}, \quad x_i \geq 0 \label{eqn:lca}
\end{equation}
where $u_i(t)$ are the external inputs, $\kappa$ is the leak rate, $\lambda$ the lateral inhibition, and $\tau$ the integration time-constant.
Each state variable $x_i$ is kept non-negative by setting negative values to 0.
Intuitively, each state variable integrates its input with leak term of $-\kappa x_i$ and provides lateral inhibition to all other state variables.
Given one input $u_i > u_j$ for all $j \neq i$, the state variable $x_i$ will converge to $u_i$ while all other state variable $x_j, j \neq i$ will converge to $0$ if $\kappa = \lambda = 1$ (TODO appendix).
In the following analysis, $\kappa = \lambda = 1$ will be fixed.
Other choices of $\lambda$ affect the effective integration time-constant $\tau$ and gain on the input, while changing $\beta$ will result in undesired behaviour (TODO ref/appendix).

By means of priniciple 3 of the NEF, the prescribed dynamics can be exactly implemented in the NEF\@.
Here, one ensemble per state variable is used (TODO figure) and the gains and biases of the neurons are distributed as described in TODO to ensure the rectification of the state variables.


\section{Independent accumulator model}\label{sec:ia}
The dynamics of the independent accumulator (IA) model are given by
\begin{align}
    \od{x_i}{t} &= \frac{1}{\tau_1} u_i(t) + \frac{1}{\tau_2} \del{\bar{x}_i - \bar{\lambda} \sum_{j \neq i} \bar{x}_j}, \quad x_i \geq 0 \\
    \bar{x}_i &= \Heavi(x_i - \vartheta)
\end{align}
where $u_i(t)$ again gives the external input, $\tau_1$ and $\tau_2$ are feedforward and feedback time-constants, $\bar{\lambda}$ is an inhibition constant, $\Heavi$ is the Heaviside step function, and $\vartheta$ is a threshold.
The Heaviside non-linearity is the crucial difference to the LCA model as we can reduce this equation to \cref{eqn:lca} by setting $\tau = \tau_1$, $k = -\tau_1/\tau_2$, and $\lambda = \bar{\lambda} \tau_1/\tau_2$ when not considering the Heaviside function.
Through the Heaviside function, the accumulators will act as perfect (opposed to leaky) and independent integrators.
Only when the threshold $\vartheta$ is reached, the winning choice will be stabilized by feedback while all non-winning choices will be inhibited.

These dynamics can again be neurally implemented by means of the NEF\@.
While for the LCA model a single layer was sufficient, it is best to use two layers to implement the IA model.
The first layer consists of independent accumulators representing the state variables $x_i$.
This layer projects to the second layer that performs the computation of $\bar{x}_i$ (i.e.\ the Heaviside function).
The second layer projects back to first layer and can be used to read out the output of the network.

\section{Comparisons of the WTA networks}
The pure analytical description does not tell which network is better suited for certain tasks.
To compare these networks, I simulate them with an input of $u_i = u - s\del{1 - \krond_{1i}} + \eta_i$, where $u$ is the magnitude of the largest input, $s > 0$ is the target separation, $\krond$ is the Kronecker delta, and $\eta_i$ is Gaussian white noise with a standard deviation of $\sigma$.
Here, without loss of generality as we can reorder the indices, the first input is always set to be the target and all other inputs are set to be lower by $s$.
The rationale behind this is that it should present the hardest case because every is close to the largest input.
As $s \rightarrow 0$, the problem will get more difficult as the separation of the target shrinks.
Note, that $u$ determines the general baseline of inputs in addition to the value of the largest input.
Furthermore, it is important to consider the influence of noise $\eta_i$ on the robustness of the decision process.

As the input lists to the CUE model will be about 10 to 12 items, I compare the networks $d=10$ choices.
To make a fair comparison 200 LIF neurons are used per choice in either model.
In the IA model this means, that the number of neurons is split between the first and second layer.
Here I use 150 neurons in the first, and 50 neurons in the second layer.
As the first layer is performing the evidence accumulation it needs to more accurate and requires more neural resources.
Due to the lower number of neurons in the output layer, the decoded output has a higher variance.
This, however, is not as relevant as the variance in interpreting the output.
If all other choices do not produce an output, the winning choice can still be clearly identified despite the variance.

Given this basic setup of the comparison, a number of metrics give insight in the performance of the networks.
First, we want the network to reach a \emph{clear decision} which I define as exactly one output being above a threshold of \num{0.15} during the time interval from \SIrange{1}{2}{\second} simulation time while all other outputs remain below the threshold.
The threshold of \num{0.15} was chosen as it is usually sufficient to tell a zero and non-zero signal apart despite spiking noise (except for very low neuron numbers or firing rates).
This metric requires that the output does not change during the interval as this might cause problems in downstream networks that operate on the output.
Also, with a change in output it would be unclear which output should be taken as the actual decision.
One thing this metric does not take into account is whether the output corresponds to the highest input.
This, whether a decision is \emph{correct}, is the second metric.
But note, that in some situations within larger scale network a wrong, but clear decision, can be preferable to a decision that tends to be correct, but is unstable.

Two more metrics are used for all trials that reached a clear decision.
The amount of time taken to fulfill the conditions for a clear decision are considered as the \emph{decision time}.
It measures how fast the network is obtaining the decision.
Finally, the networks can produce transient outputs unrelated to the final decision.
A downstream network might consider this output as an actual decision and thus those transient outputs should be as small as possible.
The \emph{highest output of a losing choice} during the whole simulation is taken as a metric for this.


\subsection{Results}
Figure~TODO shows the proportion of trials that the LCA network reaches a clear decision for different input parameters.
The input magnitude $u$ must be large enough to reliably exceed the \num{0.15} detection threshold under noise.
For $u = 0.2$ and even low amounts of noise the network fails to reach a clear decision.
However, it seems that a input magnitude too large decreases performance as well when we compare the performance for $u=0.6$ and $u=1$.
Increasing the noise standard deviation $\sigma$ or decreasing the target separation $s$, both decrease the performance as this makes the problem harder.
Interestingly, the IA network does not fail to reach a clear decision in any of these conditions.

Moving on to correct decisions, the LCA network always produced the correct output given it produced a clear decision.
The IA network, may produce incorrect outputs despite a clear decision (TODO figure).
Again, as the problem gets harder either by decreased target separation or increased noise, the network performance on this metric decreases.
Note that the feedforward integration time-constant can be increased to integrate evidence over a prolonged time period  to increase performance on this metric (right-most panel).

This, however, will increase the decision times.
These tend to be already slower for the IA network than for the LCA network (TODO figure).
Additional noise can shorten the decision times in the IA network as it increases the likelihood of an integrator randomly accumulating enough evidence to cross the threshold.
For the LCA network the noise level only has a minor influence on the decision time and was averaged over in the plot.
In other words, noise in the LCA network influences whether a decision can be reached, but not how long it takes to reach a decision if one is reached.

Finally, both networks might produce a transient response (TODO figure).
This is inherent in the LCA network because the state variables are directly used as output and gets worse with increased noise.
In the IA network, this transient response is caused when two accumulators cross the threshold in close temporal proximity before the inhibition from the first one can silence the remaining accumulators.
By increasing the feedforward time-constant, this transient response gets reduced as the evidence integration gets slowed down and this temporally stretches out when accumulators cross the threshold.


\subsection{Discussion}
Neither network performs better on all metrics.
Thus, each is best suited for a different purpose.
In situations where a continuous adjustment of a decision is necessary, the LCA network will most-likely be the better choice.
Under noisy conditions it is not necessarily able to produce a stable, clear output, but if a clear output was obtained, it was always correct.
If the input changes, the output will adjust according to the networks time constant and allow for continuous updates.
Unfortunately, this also makes the network susceptible to noise.

The IA network will be better for discrete series of decisions.
It does not produce a continuous output, but waits until the evidence integration threshold is crossed at which point the network needs to be inhibited to be reset and obtain another decision.
While this produces sequential and discrete decisions, it has the advantage that evidence can be accumulated over a longer time frame to average out noise.
Depending on the choice of the integration time-constant, the IA network will either be not as quick or as reliable in identifying the correct winner as the LCA network.
However, it will eventually produce a clear decision that a downstream network can act on (as long as at least on input is strictly positive).
This can be important in a larger scale model where stalling a decision indefinitely can result in a breakdown of model behaviour.
Or in other words, sometimes it is better to act on a wrong decision that to not act all.
For example, in memory recall it might be better to produce a wrong output and continue to recall the next item than indefinitely trying to recall an item that cannot be recalled.
It is also worth pointing out that the IA network allows for dynamic control of the decision speed by adjusting the $\vartheta$ threshold through a bias input to the second layer.

As mentioned it is also important to consider the transient outputs of the network within a larger scale model.
Such transient responses are inherent in the LCA model as the state variable is directly used as an output.
One could pass the output through a thresholding layer, but the right choice of threshold is not clear as the output magnitude will depend on the input magnitude.
If the threshold is too low, a transient response would be produced even with the thresholding layer.
If it is too high, small inputs might not produce an output at all.
While the IA can also produce transient responses, these can be reduced to almost zero by a proper selection of the integration time-constant according to the input magnitude and target separation.

By increasing $\tau_1 \rightarrow \infty$, the IA discrimination ability can be increased without bound.
This is sometimes used as argument to criticize these sort of models (TODO ref) because there is no sensible stopping criterion.
However, this does not consider that there might be a cost to come to a decision.
If that cost is included, there is a trade-off between accurate decisions and the cost incurred by taking more time to decide.
Furthermore, this argument also assumes perfect integration accuracy which an actual neural system cannot have due to neural noise and limited neural resources.

To summarize these findings, for the recall of items in memory experiments the IA network is more suited.
Such recall requires discrete decisions and a stable input to downstream motor systems producing the response.
Such a stable input cannot be guaranteed with the LCA network and it provides challenge to detect when a recall is completed.
TODO ref still used the LCA network for modelling the recall, but it is important to highlight that they upon reaching the decision threshold the state variable where immediately set back to zero.
This is easy to do in a pure math model, but when transitioning to a full neural model detecting the decision and resetting the state variables is much more difficult as it cannot be done instantaneous.

Finally, let us consider the biological plausibility briefly.
Both networks where simulated in spiking neurons which ensures a certain degree of biological plausibility.
Also, accumulation of evidence to a threshold is a well known finding for neurons in LIP (TODO ref).
Often this is assumed to be a gradual integration, but when looking at individual trials instead of the trial-average, a distinct step response becomes evident (TODO ref).
This matches the output of the second layer of the IA network.
However, both networks have in integration layer with gradually increasing firing rates which implies that such neurons should exist too.
Ultimately, I also want to highlight that this is not as issue which of these two networks is the \emph{one} network employed in the brain.
It is certainly possible, that the brain employs both networks for different tasks as they have different strengths and weaknesses.


\section{Recall network}
The recall network in the CUE model is based on the independent accumulator network.
Each potentially recallable item is regarded as one choice.
An additional choice is added to represent a failed recall.
This is a stand-in for additional items that might be present in the recall network, but have not occurred in the learned list.
It is also a way of providing a time-limit on trying to recall a particular item and prevents pure noise resulting in a successful recall of one of the learned list items.
The additional choice is fed a constant signal of TODO\@.

TODO noise

Furthermore, the IA network is embedded into further components.
First, items are represented as Semantic Pointers, but the IA network needs a separate utility value for each potential choice.
Thus, the incoming connection uses the matrix collecting the Semantic Pointers of all possible list items as transform, effectively calculating a dot product between the input signal and each potential item.
These utility values are then rectified to only consider positive evidence.
By subtracting TODO OSE threshold from the input utilities provided by the OSE output, the TODO OSE threshold is implemented.

The IA network does not produce an output during the evidence accumulation phase.
It is, however, helpful to have a persistent output of the last recalled item (note that this is still different from the output of the LCA network).
To achieve this, the output of the IA network is routed through a gated memory that is only updated when the IA network produces an output.
As the gated memory stores a Semantic Pointer, a transform matrix needs to be applied to the IA output to project the choice back into the Semantic Pointer space.
The updating is controlled by inhibiting the memory gate by default and disinhibiting it (by inhbiting the inhibitory population) when the IA network produces output.

Repetition errors are rarely made in recall experiments.
Thus, it is necessary to inhibit already recalled items.
However, this inhibition should not happen immediately as otherwise the recall output would be inhibited to quickly for downstream network to act upon.
Thus, a two-stage process is used.
First, an initial working memory population gets immediately updated by feeding in the current recall.
This will add the recalled Semantic Pointer into the representation of items to inhibit.
From that representation and the current recalled item, a dot product is calculated and thresholded add TODO\@.
Once the threshold is crossed the gate to the memory population is inhibited as the new item should be added into the representation, but not completely overwrite it.
The output of that memory population is fed to a gated memory that provides the inhibition to recall state.
The gate for this memory is controlled externally and disinhibited once the downstream processing has completed.
Note that the output of that memory population is projected back into utility values and thresholded to prevent positive evidence from the inhibition memory.

Finally, the recall network needs to be reset if a recall fails to allow to continue trying to recall the item for the next position in serial recall.
Here the proble is, that if the IA output for a failed recall is directly used to inhibit the IA network to reset it, this will also immediately inhibit the output used for the inhibition.
This will not reliably reset the network as the reset signal is disabling itself.
Thus, the signal will be fed to an integrator until a threshold is reached and then the signal of the integrator is used to provide an inhibitory pulse to the IA network.
The slower decay of the integrator ensures a sufficient length of the pulse to restart the recall process.
